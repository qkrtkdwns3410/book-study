## 처리율 제한 아키텍처

### 추가적으로 Spring Cloud Gateway + Redis LimitLimiter 조합은

- redis 명령을 Lua Script 기반으로 동작하게 사용한다고함.

### 결국에 레디스로 네트워크 지연이 존재한다.

- 미들웨어에서 → 레디스로 간다고해도

    - 결국 네트워크 통신이다.
- 모든 요청마다 redis 를 hit 해야하기에, 내부적으로 로컬 캐싱도 필요하지 않을 까 싶다.

- 로컬 캐싱을 정말정말 극단적으로 짧게 잡아서, 조금이라도 레디스 부하를 줄일 수 있지 않을까?

    > 로컬 캐싱을.. api 사용량을 넘은 사용자만 별도로 캐싱해두어서 ( 대충 n 천 ~ 만명정도만?)
    >
    > - 그 사람들은 redis 방문을 할 필요도 없이 로컬 캐싱에서 429 반환하는 것도 좋은 방법일듯?
    >
    > 또한
    >
    > - 사용자당 api 호출 한도데이터의 경우 거의 불변데이터이기에, 로컬 캐싱에 담는것도 나쁘지 않을듯.


### 레디스가 죽어버리면 어떻게 할지

1. 그냥 다 통과 → 이게 일반적일듯?
2. 그냥 다 막기 ( 이런 서비스가 있을지..? ) 모르겠네

# 상세 설계

### 단순 카운터나 버킷으로도 충분할까?

- api 마다 평균 응답시간 등의 cost 가 다를텐데, 가중치를 부여할 필요가 있지 않을까?
- 가벼운 api 는 토큰 1개, 무거운거는 10개 이런식으로

### 재시도 로직 구현시 → 충분한 백오프

- 백오프의 부작용
    - 1초뒤에 재시도 → 2초뒤에 재시도 이런식으로 고정된 백오프가 가지면, 동시에 거절당한 수많은 클라이언트가 똑같은 시간대에 다시 몰려와서
    - 2차 충격을줌 ( Thundering Herd )
        - 랜덤 값인 ( Jitter ) 를 통해 1.5초~ 2.5 초 사이의 랜덤 대기를 두는 것이 좋다.
### Line 에서의 고 처리량 분산 비율 제한기 (https://engineering.linecorp.com/ko/blog/high-throughput-distributed-rate-limiter)
- 1월 1일 자정 LINE 에서는 연중 최고 트래픽이 발생하는 NEW YEAR 캠페인이라는 게 있다고 함.
- 사용자 경험을 해치지 않기 + 내부 MSA 에 과부하가 걸리지 않도록 보호하기 위한 방법
- 서버 측에서 요청 거절 X => 클라이언트(컨슈머) 에서 발송 속도를 조절하는 비율 제한기 도입
#### 아키텍처 설계 관련
- 기존의 REDIS 의 경우 중앙 집중식 방식 -> 초당 30만건 이상의 요청을 처리하기 어렵다고 판단.
- 분산 인메모리 방식을 선택했다고 함

|*비교 항목*|*중앙 저장소 방식 (Redis 등)*|*분산 인메모리 방식 (채택)*|
|---|---|---|
|*구조*|모든 카운터를 Redis 등 외부 저장소에서 관리|각 소비자 인스턴스가 로컬 메모리에 카운터 관리|
|*장점*|구현이 간단함, 정합성 보장 쉬움|*지연 시간 없음(No Network I/O)*, 높은 확장성|
|*단점*|네트워크 지연(RTT), 병목 현상 및 SPOF 위험|인스턴스 간 동기화 필요, 트래픽 불균형 시 효율 저하|
- N 분의 1 전략
	- 분산형 인메모리 방식은 `각 창구 직원에게 미리 번호표 뭉치를 나눠주고 알아서 나눠주게 하는 것`이다.
	- 계산 방식으로는
		- 전체 시스템이 허용해야 할 총 트래픽 양을 현재 떠 있는 인스턴스의 수로 나누는 것임.
	$$InstanceLimit = \frac{TotalLimit}{Number Of Consumer Instances}$$
	- API 서버 초당 1,000건 허용 -> 내 서버 10대 ,  각 서버 초당 100건 까지만 자체 메모리에서 카운팅해서 처리
- 해당 방식이 제대로 돌아가기 위해서는 2가지 장치가 필요
	1. 설정 서버의 분리 ( Central Dogma )
		- 센트럴 도그마 :  LINE 에서 만든 오픈소스임 모든 설정 정보를 중앙제어할 수 있는 라이브러리 ( https://github.com/line/centraldogma ) -> 서버 재시작없이 yml 이나 json 반영 가능함. (재시작시 로컬 카운터 초기화 문제 방지)
	2. 시간 동기화
		- 각 서버가 시간적으로 동기화 되어 있어야 정확한 rate limter 가능..
- 제한량을 넘어버릴수있다.
	- 서버 한도가 1000개 인데, 999개일때 서버 재시작 -> 0으로 카운터 초기화 또다시 1000개 사용 => 1999 호출이 가능한 상황
	- Line 에서는 이 정도의 오차는 감수 => 고성능
- 일단 사용하는게 라인의 경우 TPS 기준으로 카운팅하는듯 ( 초당 api 제한 몇개 .. 이런식으로)