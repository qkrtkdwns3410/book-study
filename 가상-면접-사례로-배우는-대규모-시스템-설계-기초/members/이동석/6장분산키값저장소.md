# 부가설명 W+R > N  강한 일관성, 최신 데이터 보장에 대하여

네, 마지막 문장은 분산 시스템의 **정족수(Quorum) 합의** 원리에 기반한 아주 정확한 설명입니다.

결론부터 말씀드리면,  조건은 **비둘기집의 원리(Pigeonhole Principle)**에 의해 읽기 작업 시 반드시 최소한 하나 이상의 최신 데이터(가장 최근 쓰기가 완료된 노드)를 만나게 됨을 보장합니다.

W=2, R=2, N=3인 상황으로 증명해보자.

요청하신  케이스로 증명해 보겠습니다.

---

## 1. 정족수(Quorum) 시각화 증명

노드가 3개()인 상황에서 와 를 적용해 봅시다.

### Step 1: 쓰기 연산 ()

데이터를 업데이트할 때 3개 중 2개의 노드에 성공적으로 기록해야 합니다. 가능한 조합은 다음과 같습니다.

- {1, 2}에 기록
- {2, 3}에 기록
- {1, 3}에 기록

가령, 우리가 **{1, 2}** 노드에 최신 데이터를 썼다고 가정합시다. (노드 3은 예전 데이터를 가집니다.)

### Step 2: 읽기 연산 ()

이제 데이터를 읽기 위해 3개 중 2개의 노드에서 응답을 받아야 합니다. 가능한 조합은 다음과 같습니다.

1. *{1, 2}**를 읽음 노드 1, 2 모두 최신 데이터 보유 (**성공**)
2. *{2, 3}**을 읽음 노드 2가 최신 데이터 보유 (**성공**)
3. *{1, 3}**을 읽음 노드 1이 최신 데이터 보유 (**성공**)

### Step 3: 결론

어떤 조합으로 읽더라도, 최소한 1개의 노드(위 예시에서는 노드 1 또는 2)는 반드시 쓰기 집합()과 읽기 집합()에 동시에 포함됩니다.


# 충돌 해소의 방식. 뭘 어떻게 한다는 것인가

분산 시스템에서 벡터 시계(Vector Clock)를 통해 충돌(Conflict)을 감지했다는 것은, **"서로 다른 두 클라이언트가 동일한 데이터의 이전 상태를 기반으로 각자 다른 수정을 가했다"**는 것을 의미합니다. 시스템 입장에서는 어떤 것이 최종본인지 판단할 수 없으므로, 이를 클라이언트에게 던져주며 "직접 합쳐줘(Merge)"라고 요청하게 됩니다.

이를 **'형제(Sibling) 데이터 생성'**과 **'클라이언트 측 병합(Client-side Merge)'**이라고 부릅니다. 구체적인 예시로 설명해 드릴게요.

---

### 예시: 쇼핑몰 장바구니 (Conflict Resolution)

상황: 사용자 A와 B가 하나의 공유 계정 장바구니에 물건을 담고 있습니다. 현재 서버의 장바구니 상태는 `['사과']`이고 벡터 시계는 `{A:1}`입니다.

### 1. 충돌의 발생

- **클라이언트 A의 작업:** 사과가 있는 상태에서 '배'를 추가합니다. 서버에 보낼 데이터: `['사과', '배']`, 벡터 시계: `{A:2}`.
- **클라이언트 B의 작업 (동시에):** 사과가 있는 상태(A:1)에서 '포도'를 추가합니다. 서버에 보낼 데이터: `['사과', '포도']`, 벡터 시계: `{A:1, B:1}`.

서버는 이 두 데이터를 모두 받으면, 벡터 시계를 비교해보고 **인과 관계가 없음(충돌)**을 감지합니다. 이때 서버는 데이터를 하나로 덮어쓰지 않고, **두 버전(형제 데이터)을 모두 저장**합니다.

### 2. 클라이언트의 충돌 해소 (어떻게 하는가?)

사용자가 다음에 장바구니를 조회하면, 서버는 두 가지 버전을 모두 내려줍니다.

> 서버 응답: "충돌이 있어! 여기 두 가지 버전이 다 있으니 네가 합쳐줘."
>
> - v1: `['사과', '배']` (벡터 시계 {A:2})
> - v2: `['사과', '포도']` (벡터 시계 {A:1, B:1})

이제 클라이언트는 미리 정의된 **비즈니스 로직**에 따라 이를 해소합니다.

- **방법 A: 합집합 (Set Union)**

    장바구니의 경우, 물건이 누락되면 안 되므로 보통 합집합을 선택합니다.

    - 결과: `['사과', '배', '포도']`
- **방법 B: 마지막에 쓴 사람이 이김 (LWW, Last Write Wins)**

    타임스탬프를 비교해 가장 최근 시간을 선택합니다.

    - 결과: (더 늦게 도착한) `['사과', '포도']`
- **방법 C: 사용자에게 직접 물어보기**

    "두 가지 버전이 있습니다. 어떤 것을 유지할까요?"라고 화면에 띄웁니다. (구글 드라이브나 Git의 충돌 해결 방식)


### 3. 해소 결과 반영

클라이언트가 **합집합(방법 A)**을 선택해 `['사과', '배', '포도']`로 합쳤다면, 이 결과물을 다시 서버에 보냅니다. 이때 벡터 시계는 두 버전을 합쳤음을 증명하기 위해 **두 시계를 병합하고 자신의 카운트를 올립니다.**

- 새로운 데이터: `['사과', '배', '포도']`
- 새로운 벡터 시계: `{A:3, B:1}` (A:2와 {A:1, B:1}을 합친 후 A가 업데이트함)

이제 서버는 이 새로운 벡터 시계를 보고 "아, 이전의 충돌했던 두 버전이 이 데이터로 합쳐졌구나!"라고 이해하고 기존의 형제 데이터들을 삭제한 뒤 이 최종본만 남깁니다.

---

### 요약하자면 "해소"란?

1. **감지:** 서버가 벡터 시계를 비교해 충돌을 확인하고, 데이터를 버리지 않고 모두 보관함.
2. **전달:** 클라이언트가 데이터를 읽으려 할 때 서버는 충돌된 모든 버전을 다 줌.
3. **병합:** 클라이언트가 로직(합집합, 사용자 선택 등)에 따라 데이터를 하나로 합침.
4. **확정:** 합쳐진 데이터와 병합된 벡터 시계를 서버에 다시 써서 충돌 상황을 종료시킴.

결국 **"해소"**는 시스템이 자동으로 하는 것이 아니라, 데이터의 성격에 맞게 **개발자가 짠 코드(로직)나 사용자의 선택**을 통해 이루어지는 과정입니다.


# 블룸필터

## 블룸필터란 무엇인가, 무슨 원리인가

- https://www.devkuma.com/docs/data-structure/bloom-filter/
- 이 자료를 보자.

## 블룸 필터의 증명. 귀류법 (Proof by Contradiction)

어떤 명제가 참임을 증명하기 위해, 그 반대 상황(부정)을 가정했을 때 **모순(Contradiction)**이 발생함을 보여줌으로써 원래의 명제가 참일 수밖에 없음을 증명하는 방법입니다. 한자어로는 '거꾸로(歸) 미루어(謬) 판단하는 법'이라는 뜻을 가집니다.

당신의 논리를 대입해보면 이렇습니다:

- **증명하려는 것:** "Element3은 그룹에 없다."
- **반대 가정:** "Element3이 그룹에 있다고 치자."
- **논리 전개:** "있다면 모든 해시 값 위치가 1이어야 한다."
- **모순 발견:** "그런데 실제로는 0인 곳이 있다!"
- **결론:** "가정이 틀렸으므로 Element3은 없는 게 확실하다."

## 블룸 필터를 다른 일반적 필터와 비교해보자.
| 비교 항목 | 블룸 필터 (Bloom Filter) | 일반적 필터 (Hash Set / List) |
|---|---|---|
| **공간 복잡도** | 매우 낮음 (O(m) 비트)<br>데이터 원본 없이 비트만 저장 | 높음 (O(n) 바이트)<br>데이터 원본 또는 포인터 저장 |
| **조회 속도** | 매우 빠름 (O(k))<br>데이터 크기와 무관하게 일정 | 빠름 ~ 보통 (O(1) ~ O(n))<br>충돌 증가 시 성능 저하 가능 |
| **정확도 (Positive)** | 확률적 (오탐 가능)<br>“있을 수도 있다” | 결정적 (100% 정확)<br>“확실히 있다” |
| **정확도 (Negative)** | 100% 확실<br>“없음”은 절대 틀리지 않음 | 100% 확실<br>“없음”은 절대 틀리지 않음 |
| **데이터 보존** | 불가능<br>어떤 데이터가 들어있는지 확인 불가 | 가능<br>저장된 데이터 목록 확인 가능 |
| **주요 용도** | 대용량 데이터의 존재 여부 1차 필터링 | 소량 ~ 중량 데이터의 정확한 관리 |

## 블룸 필터의 성능

**2. 성능을 결정하는 수학적 공식 (공식 자료)**
블룸 필터의 설계 공식은 통계적으로 정립되어 있습니다. 원하는 오탐률($p$)을 얻기 위해 필요한 비트 배열의 크기($m$)와 해시 함수의 개수($k$)를 계산하는 공식은 다음과 같습니다.
1. **필요한 비트 수 ($m$):** 데이터 개수($n$)와 원하는 오탐률($p$)이 주어졌을 때$$m = - \frac{n \ln p}{(\ln 2)^2}$$

![필요한비트수공식](https://wikimedia.org/api/rest_v1/media/math/render/svg/5a90ab21c84c30f655ae6b0b9ea78a407738a487)

*(예: 데이터 100만 개에 대해 1% 오탐률을 원하면 약 960만 비트(약 1.2MB)가 필요합니다.)*

2. **최적의 해시 함수 개수 ($k$):**$$k = \frac{m}{n} \ln 2$$
*(비트 배열이 클수록 더 많은 해시 함수를 써서 촘촘하게 검사하는 것이 유리합니다.)*

![최적의해시함수개수공식](https://wikimedia.org/api/rest_v1/media/math/render/svg/fabc2770225ac59fe42a78f75ea89de650f0130c)

위의 예시로 하면 대충 해시함수 10개면 된다! 와우!