# 책의 내용 정리

일반적인 캐시의 키를 여러대의 서버대에 저장할때 일반적으로 모듈러(나머지) 함수를 이용해 저장한다고 치자, 이때 1번 서버가 죽으면 대부분의 데이터가 없는 캐시서버에 접속한다. 대규모 캐시 미스 발생. 안정 해시는 이 문제를 효과적으로 해결하는 기술

k/n의 키만 재배치하는 기술

k : 키의 개수

n : 슬롯의 개수

참고 해시함수 : 가변길이의 문자열을 고정길이의 문자열로 변환하는 함수. 입력 x에 대하여 f(x)=y일 경우, 함수가 여려번 실행된다고 해도 같은 결과를 보장한다.

이런 안정 해시 알고리즘의 기본 절차는 아래와 같다.

1. 서버와 키를 균등 분포 (uniform distribution) 해시 함수를 사용해서 해시 링에 배치
2. 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버

# 책 참고문헌 해석하면서 알게된 자료 정리

## **Discord는 어떻게 Elixir를 사용하여 동시 접속 사용자 500만 명을 수용하도록 확장했을까요?**

https://discord.com/blog/how-discord-scaled-elixir-to-5-000-000-concurrent-users

### elixir는 진짜 동시성 처리에 성능이 뛰어난가? 벤치마크 자료 확인

https://www.erlang-solutions.com/blog/comparing-elixir-vs-java/

위 자료에 따르면 elixir은 java와 같은 조건에서 아래 와같은 차이를 보였다.

구글 컴퓨트 노드

- CPU 정보: AMD EPYC 7B12
- 사용 가능한 코어 수: 8
- 사용 가능한 메모리: 31.36GB

![elixir와 자바의 비교](https://lh7-eu.googleusercontent.com/9yY8Lp7tcsmHXxvvrZkkXYeTMjBFwAKSr6P0sm5B26DmjwtGb2GHxFGUOnjCAXVRSSD9SOxvnTvIzmcLkCz7WUmt9Ng4AjBaz90RlIh-7RyC145ikrx3zlrTS8271VIsM3sDD0sWaw0BNYmXdFfCO94)

5000개이상의 동시성 과제를 처리하며, 충분히 빠른 속도로 동작

https://themindstudios.com/blog/why-choose-elixir-for-your-project/

- elixir는 actor model의 사용으로 동시성이슈(데드락 이슈 없음. 복잡한 락 메커니즘 필요 없음.)를 해결.
  - 액터 모델은 상태를 공유하지 않으므로 복잡한 락 메커니즘 없이도 동시성을 안전하게 처리합니다.

### 그렇다면 디스코드는 어디서 어떤 타이밍에 consistent hashing 을 적용하였는가?

#### 1. 핵심 활용 포인트: 실시간 세션 관리 (Gateway)

Discord는 사용자가 접속하면 WebSocket 연결을 유지하는 **Gateway 서비스**를 운영합니다. 이때 특정 사용자의 연결이 어느 서버 노드에 할당될지를 결정할 때 컨시스턴트 해싱을 사용합니다.

- **상태 유지(Stateful):** 각 서버는 연결된 클라이언트의 세션 정보를 들고 있어야 합니다.
- **노드 추가/제거 시 영향 최소화:** 서버 한 대가 죽거나 트래픽 증가로 새 서버를 투입할 때, 일반적인 `hash(user_id) % n` 방식을 쓰면 `n`이 변하는 순간 거의 모든 연결이 끊기고 재접속 대란(Thundering Herd)이 일어납니다.
- **해결:** 컨시스턴트 해싱을 사용하면 서버가 추가/삭제되어도 **해당 노드에 할당되었던 최소한의 연결만 재배치**하면 됩니다.

#### 2. 메시지 전송 작업의 분배
- 메시지 전송 작업(이벤트)을 워커노드에 분배할때 안정해시를 활용.

![메시지전송작업의 분배 예시 이미지by gemini](./images/message_event_hashing.png)

12시방향 userA, 6시방향 사람, 그리고 노드의 색깔은 무시하고 봅시다.

- userX가 활성화상태야를 길드내의 유저들에게 이벤트를 전달할때 consistent hashing을 사용한다.
    - 따라서 얻을수 있는 장점
        1. 혹시나 처리할 프로세스의 수가 증가하거나 감소할때 최소한의 유저들에(키만)만 영향이 가도록(키의 재배치. 키의 재배치중 메시지 전달이 원할하지 않을 가능성) 처리 가능.
        2. 선형성(Linearizability, 작업의 순서가 뒤바뀌지 않는 성질)을 보장한다.



#### 3 Manifold의 작동 방식
- (3단계, 참고용. 2번의 부연설명. 블로그 url의 Inspired by a [blog post](http://www.ostinelli.net/boost-message-passing-between-erlang-nodes/) about boosting performance of message passing between nodes, [Manifold](https://github.com/hammerandchisel/manifold) was born 의 해석자료.)

노드 간 메시지 전달 성능 향상에 관한 한 블로그 게시물에서 영감을 받아 **Manifold**가 탄생했습니다. Manifold는 메시지를 보낼 대상인 PID(Erlang 프로세스 식별자)들의 원격 노드로 메시지 발송 작업을 분산시킵니다. 이를 통해 메시지를 보내는 프로세스가 `send/2` 함수를 호출하는 횟수가 관련된 원격 노드의 개수를 초과하지 않도록 보장합니다.

Manifold의 작동 방식은 다음과 같습니다. 우선 PID들을 각각의 원격 노드별로 그룹화한 뒤, 해당 노드들에 존재하는 `Manifold.Partitioner`로 메시지를 보냅니다. 그 후, 이 분배기(Partitioner)는 `:erlang.phash2/2`를 사용하여 PID들을 **일관되게 해싱(Consistently Hashing)**하고, 이를 CPU 코어 수에 맞춰 그룹화하여 하위 워커(Child workers)들에게 전달합니다. 마지막으로 이 워커들이 실제 프로세스들에게 메시지를 발송합니다.

이러한 구조는 분배기에 과부하가 걸리지 않도록 보장하면서도, 기존 `send/2` 함수가 보장하던 **선형성(Linearizability, 작업의 순서가 뒤바뀌지 않는 성질)**을 그대로 유지합니다. 이 솔루션은 사실상 기존의 `send/2`를 그대로 대체하여 바로 사용할 수 있는 수준(Drop-in replacement)이었습니다.

Inspired by a [blog post](http://www.ostinelli.net/boost-message-passing-between-erlang-nodes/) about boosting performance of message passing between nodes, [Manifold](https://github.com/hammerandchisel/manifold) was born. Manifold distributes the work of sending messages to the remote nodes of the PIDs (Erlang process identifier), which guarantees that the sending processes at most only calls send/2 equal to the number of involved remote nodes. Manifold does this by first grouping PIDs by their remote node and then sending to Manifold.Partitioner on each of those nodes. The partitioner then consistently hashes the PIDs using :erlang.phash2/2, groups them by number of cores, and sends them to child workers. Finally, those workers send the messages to the actual processes. This ensures the partitioner does not get overloaded and still provides the linearizability guaranteed by send/2. This solution was effectively a drop-in replacement for send/2:

### 공유 데이터 접근 최적화
* 앞서 설명한것처럼 디스코드는 안정해싱 기술을 분산처리를 위해 활용한다.
  * 문제 발생
    * 링 조회시 오버로드가 있었음.
      * 기존 비용 : 약 30초
      * 원인 파악해보니, 기존에 Elisir의 ETS라는 저장 공간을 활용했는데 이것은
        * ETS : ETS(erlang term storage)는 Elixir 및 Erlang 객체를 위한 내장형 내장 메모리 저장소로, 강력한 성능을 제공합니다. ETS는 대량의 데이터를 저장할 수 있으며, 상수 시간 데이터 접근을 지원합니다.
        * ETS 입출력시 복사 비용이 컸음.
          * 공유하는 프로세스들이 접근하는 내장 메모리 저장소인데, 프로세스들이 주기적으로 본인의 ETS를 업데이트 해야했고, 그 비용이 컸다.
        * https://elixirschool.com/en/lessons/storage/ets#/
    * 해결 : chiglobal 발견: 연구 끝에 mochiglobal 모듈을 발견했습니다.  이 모듈은 Erlang VM의 특정 기능을 활용하는데, 함수가 항상 동일한 상수 데이터를 반환하면 VM이 해당 데이터를 읽기 전용 공유 힙(read-only shared heap)에 넣어 프로세스들이 데이터를 복사하지 않고 접근하게 합니다.
      * TOBE : 총 조회 750ms 이내.

#### 왜 ETS는 "조회"인데도 복사가 발생할까
* Elixir(Erlang VM)는 프로세스 격리 모델을 사용한다.
* 각 프로세스는:
  * 자기만의 힙 메모리를 갖고
  * 다른 프로세스 메모리에 직접 접근하지 못한다
* ETS는 공유 메모리 영역에 존재하지만, ETS 테이블의 데이터는 프로세스 힙에 직접 매핑되지 않는다.
```
[ETS 테이블]  <-- 공유 메모리
     |
     |  (읽기 요청)
     v
[프로세스 A 힙]  ← 복사됨

```

### 제한된 동시성 제어
* 새로운 문제는 약 500만 개의 세션 프로세스가 각 길드 노드에 있는 10개의 프로세스에 동시적으로 접근하려 하면서 발생했습니다.  이 경로를 빠르게 만드는 것만으로는 해결되지 않았습니다.
  * 문제의 심화: 세션 프로세스가 길드 레지스트리에 대한 호출이 타임아웃되면 요청이 레지스트리 큐에 남게 됩니다.  이후 백오프(backoff) 후 재시도되지만, 요청이 계속 쌓여 복구 불가능한 상태에 빠집니다.

  * 연쇄 장애: 세션 프로세스들은 다른 서비스로부터 메시지를 받는 동안 이러한 요청들이 타임아웃될 때까지 차단되었고, 이로 인해 메시지 큐가 부풀어 올라 결국 Erlang VM 전체가 OOM(메모리 부족) 상태가 되어 서비스 중단으로 이어졌습니다.
  * 일시적 대안 : 서킷 브레이커.
    * 세션 프로세스가 실패가 확실할 경우 아예 길드 레지스트리에 호출하지 않도록 더 똑똑해져야 했습니다.  서킷 브레이커(circuit breaker)를 사용하고 싶지 않았는데, 이는 타임아웃 버스트가 발생했을 때 일시적으로 모든 시도가 중단되는 임시 상태를 초래하기 때문입니다.

* 동시성제어를 위한 Elixir용 세마포어 라이브러리 개발
  * 라이브러리 구현 핵심 : ets.update_counter/4 함수를 발견했습니다.  이 함수는 ETS 키 내의 숫자에 대해 원자적 조건부 증가 연산을 지원한다.
* 이동석 해석 :
  * 해당 세마포어를 사용하여 다음 처럼 바꿈.
    * ASIS : 기존에는 타임아웃날때 까지 대기하던 메시지때문에 OOM 등 발생
    * TOBE : 각 프로세스별 최대 동시 호출을 특정 수치로 제한. 그 구현으로 만들어둔 세마포어 라이브러리를 활용. 동시성 수준 X을 초과하는 요청들은 빠르게 실패하도록 처리(조기 이탈), 메세지의 큐대기 없고, OOM 탈출.