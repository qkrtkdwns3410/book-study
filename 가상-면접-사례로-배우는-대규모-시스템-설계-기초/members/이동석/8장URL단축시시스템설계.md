# base62란?

- https://en.wikipedia.org/wiki/Base62
- 이진 데이터를 택스트로 인코딩하는 것을 의미한다.
    - 62개의 ASCII의 숫자와 문자로 구성한다.
        - A-Z, a-z, 0-9
        - 26 + 26+ 10
    - 주로 긴 숫자를 짧고 읽기 쉬운 문자열로 압축할 때 사용

| **특징** | **Base62** | **Base64** |
| --- | --- | --- |
| **문자 개수** | 62개 | 64개 |
| **특수 문자** | 없음 | 있음 (`+`, `/` 등) |
| **주 용도** | URL 단축키, 식별자 생성 | 바이너리 데이터 전송 (이미지 등) |
| **URL 친화성** | 매우 높음 | 인코딩 필요 (URL Safe 버전 별도 존재) |

URL 단축기는 읽기(Read) 성능을 높이기 위한 전략으로캐시를 사용한다면… 어떤 캐시? LRU 캐시? LFU캐시? 알고리즘 조사하게됨.

# 캐시 알고리즘 LRU와 LFU에 대한 조사

- LRU
    - Least Recently Used
    - 가장 오랫동안 찾지 않은 데이터를 삭제
    - 구현방식 : Doubly Linked List 자료구조 사용.
        - **Hit (성공):** 찾으려는 데이터가 캐시에 있으면, 해당 데이터를 **가장 최신 위치(맨 앞)**로 옮깁니다.
        - **Miss (실패):** 데이터가 없으면 DB에서 가져와 **맨 앞**에 넣습니다.
        - **Eviction (제거):** 만약 공간이 부족하면 **맨 뒤(가장 오래된 것)**를 삭제합니다.
- LFU
    - Least Frequently Used
        - 얼마나 자주 사용되었는가
        - 사용자가 클릭하는 횟수를 카운팅해서, "가장 인기가 없는(클릭 수가 적은) 데이터"를 먼저 삭제하는 방식
        - LFU는 각 데이터마다 **참조 횟수(Counter)**를 붙여서 관리합니다.
            - **동작:** 데이터가 참조될 때마다 해당 데이터의 카운트를 1씩 올립니다.
            - **교체:** 새로운 데이터를 넣어야 하는데 공간이 부족하면, **카운트 숫자가 가장 낮은 데이터**를 찾아 제거합니다.
            - **동점 처리:** 만약 카운트가 가장 낮은 게 여러 개라면, 그중에서 가장 오래된 것(LRU 방식 적용)을 지우는 식으로 보완하기도 합니다.
        - 자료구조
          - Hash Table (해시 테이블)빠른 접근을 위해 두 종류의 해시 테이블을 주로 사용합니다.
            - Key-Node Map: 사용자가 찾는 Key를 통해 해당 데이터가 담긴 Node에 즉시 접근합니다 ($O(1)$).
            - Frequency Map: 특정 Frequency(빈도수)를 Key로 하여, 해당 빈도수를 가진 노드들의 리스트를 관리합니다.
          - Doubly Linked List (이중 연결 리스트)동일한 빈도수를 가진 데이터들 사이에서도 **가장 오래된 것(LRU)**을 찾아내기 위해 사용합니다.특정 빈도수 내에서 데이터가 추가되면 리스트의 맨 앞에 붙이고, 삭제 시에는 맨 뒤(가장 오래된 데이터)를 삭제합니다.
- URL 단축기에서 LFU가 유리한 경우
    - URL 단축 시스템에서 LFU는 다음과 같은 상황에 효과적입니다.
    - **장기적인 인기 링크:** 특정 이벤트 페이지나 공지사항처럼, 아주 최근에 클릭된 것은 아니더라도 **꾸준히 접속이 발생하는 링크**를 캐시에 보관하고 싶을 때 유리합니다.
    - **스팸성 일시적 트래픽 방어:** 갑자기 1분 동안만 반짝하고 사라지는 무의미한 URL보다, 1년 내내 꾸준히 클릭되는 '네이버 메인' 같은 링크를 살려두기에 적합합니다.

| **구분** | **LRU (Least Recently Used)** | **LFU (Least Frequently Used)** |
| --- | --- | --- |
| **판단 기준** | 마지막 사용 시간 (최근성) | 누적 사용 횟수 (빈도수) |
| **특징** | 최근에 쓴 게 또 쓰일 것이다! | 많이 쓴 게 또 쓰일 것이다! |
| **장점** | 구현이 쉽고 반응 속도가 빠름 | 집중적인 인기 콘텐츠 관리에 탁월 |
| **단점** | 자주 쓰여도 오래전이면 삭제됨 | 과거에만 인기 있었던 데이터가 알박기함 |
- 실제 현업에서는 LFU의 단점을 보완한 **TinyLFU**나 **Sampled LFU** 같은 변형 알고리즘을 사용하기도 합니다. → 찾아보니 Caffein에서 사용
- TinyLFU
    - LFU의 가장 큰 문제점인 **"과거의 영광(높은 빈도수를 가진 오래된 데이터가 캐시를 독점하는 현상)"**을 해결하기 위해 등장한 매우 영리한 알고리즘
        - 기술적 묘수 :
            1. 모든 데이터 빈도를 숫자로 저장하면 빈도를 너무 많이 쓴다 → Count-Min Sketch 라는 확률적 자료구조사용
                - 데이터를 직접 저장하는 대신, **해시 함수**를 거쳐 비트 배열에 빈도수를 기록합니다.
                - **장점:** 아주 적은 메모리(데이터당 몇 비트 수준)만 사용하면서도 수십억 개의 데이터 빈도수를 추정할 수 있습니다.
                - **단점:** 확률적이기 때문에 실제보다 빈도가 약간 높게 측정될 수 있지만(False Positive), 캐시 정책에서는 치명적이지 않습니다.
            2. **'과거의 영광'을 처리하는 법: Reset (Freshness)**

                - TinyLFU는 일정 수 이상의 요청이 들어오면 모든 카운트를 **절반으로 나눠버리는(Divide by 2)** 'Reset' 과정을 거칩니다.

                - 이렇게 하면 과거에 1,000번 클릭되었던 데이터도 시간이 흘러 Reset을 몇 번 거치면 카운트가 낮아집니다.
                - 결과적으로 **최근에 활발하게 사용되는 데이터**가 다시 경쟁력을 갖게 됩니다.
- 참고자료 : [https://blog.imqa.io/count-min-sketch/](https://blog.imqa.io/count-min-sketch/#count-min-sketch)
    - https://arxiv.org/pdf/1512.00727

# Count-Min Sketch의 수치적 장점
* 저장공간의 크기
  * 기존 방식: 고유 아이템이 1,000만 개라면, 최소 수백 MB 이상의 메모리가 필요합니다.
  * CMS 방식: 오차 범위를 허용한다면 수십~수백 KB만으로도 1,000만 개의 데이터를 추적할 수 있습니다.
* 신뢰도: 사용자가 설정한 확률($1-\delta$, 보통 99.9% 이상)로 위 오차 범위가 보장됩니다.
* **"1,000배 이상의 공간 절약이 가능하지만, 0.1% 정도의 오차와 '약간 부풀려진 데이터'를 받아들일 준비가 되어 있다면 최고의 선택"**
